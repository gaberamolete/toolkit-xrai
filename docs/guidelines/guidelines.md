---
layout: default
title: Guidelines
nav_order: 3
has_children: true
permalink: /docs/guidelines
---

# Guidelines

This section serves as the basis regarding explainable and responsible artificial intelligence (XRAI), its principles, risk management, methodology of implementation in the department and tests to comply with the guidelines. It aims to provide information about the significance of XRAI concepts within the Data Science teams of Aboitiz.
{: .fs-6 .fw-300 }

The section serves as a guideline in assessing if a particular model, system, or data science practice adheres to XRAI principles. It shall provide a practical methodology for assessing the alignment of an DSAI system with the XRAI principles.

The scope of this document includes all models and artificial intelligence (AI) systems in development and currently deployed across DSAI. The scope of work applying the methodology shall be specific to the system under study and is calibrated to the level of risk associated with the systemâ€™s operation. The XRAI methodology and XRAI-specific methods should be applied in  consideration of and complexity of the models in study, their impact on the customers, and the on 
the financial performance or reputation of the organization.

Limitations of this document include correcting for change on systems not owned by the organization and that AI systems must adhere to laws and regulations by regulatory bodies of the organization or of the government. We would like to emphasize that this document (and accompanying toolkit) does not define ethical standards; it only aims to provide a way for DSAI System Developers and Owners to demonstrate their claims about the performance of their DSAI systems according to the XRAI principles. It also does not guarantee that any DSAI system tested using this Framework will be free from risks or biases.